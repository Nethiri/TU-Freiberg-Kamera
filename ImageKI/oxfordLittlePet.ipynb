{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\r\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\r\n",
    "\r\n",
    "import tensorflow_datasets as tfds\r\n",
    "\r\n",
    "from IPython.display import clear_output\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <PrefetchDataset shapes: {file_name: (), image: (None, None, 3), label: (), segmentation_mask: (None, None, 1), species: ()}, types: {file_name: tf.string, image: tf.uint8, label: tf.int64, segmentation_mask: tf.uint8, species: tf.int64}>, 'test': <PrefetchDataset shapes: {file_name: (), image: (None, None, 3), label: (), segmentation_mask: (None, None, 1), species: ()}, types: {file_name: tf.string, image: tf.uint8, label: tf.int64, segmentation_mask: tf.uint8, species: tf.int64}>}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='oxford_iiit_pet',\n",
      "    full_name='oxford_iiit_pet/3.2.0',\n",
      "    description=\"\"\"\n",
      "    The Oxford-IIIT pet dataset is a 37 category pet image dataset with roughly 200\n",
      "    images for each class. The images have large variations in scale, pose and\n",
      "    lighting. All images have an associated ground truth annotation of breed.\n",
      "    \"\"\",\n",
      "    homepage='http://www.robots.ox.ac.uk/~vgg/data/pets/',\n",
      "    data_path='C:\\\\Users\\\\User\\\\tensorflow_datasets\\\\oxford_iiit_pet\\\\3.2.0',\n",
      "    download_size=773.52 MiB,\n",
      "    dataset_size=774.69 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'file_name': Text(shape=(), dtype=tf.string),\n",
      "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=37),\n",
      "        'segmentation_mask': Image(shape=(None, None, 1), dtype=tf.uint8),\n",
      "        'species': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=3669, num_shards=4>,\n",
      "        'train': <SplitInfo num_examples=3680, num_shards=4>,\n",
      "    },\n",
      "    citation=\"\"\"@InProceedings{parkhi12a,\n",
      "      author       = \"Parkhi, O. M. and Vedaldi, A. and Zisserman, A. and Jawahar, C.~V.\",\n",
      "      title        = \"Cats and Dogs\",\n",
      "      booktitle    = \"IEEE Conference on Computer Vision and Pattern Recognition\",\n",
      "      year         = \"2012\",\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}