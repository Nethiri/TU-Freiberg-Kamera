{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WGeukhYh9fd"
   },
   "source": [
    "# TFDS CLI\n",
    "\n",
    "TFDS CLI is a command-line tool that provides various commands to easily work with TensorFlow Datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-42ZFIIrgbF"
   },
   "source": [
    "Copyright 2020 The TensorFlow Datasets Authors, Licensed under the Apache License, Version 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grQeV-PZroqn"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/cli\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/cli.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/datasets/blob/master/docs/cli.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/datasets/docs/cli.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGrmMPUhXfUs"
   },
   "source": [
    "##### Disable TF logs on import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T12:14:51.054425Z",
     "iopub.status.busy": "2021-02-11T12:14:51.053759Z",
     "iopub.status.idle": "2021-02-11T12:14:51.056077Z",
     "shell.execute_reply": "2021-02-11T12:14:51.055605Z"
    },
    "id": "vJLAsn1c0Hxu"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%env TF_CPP_MIN_LOG_LEVEL=1  # Disable logs on TF import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo-yMd3Zrm_K"
   },
   "source": [
    "## Installation\n",
    "\n",
    "The CLI tool is installed with `tensorflow-datasets` (or `tfds-nightly`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T12:14:51.060623Z",
     "iopub.status.busy": "2021-02-11T12:14:51.060035Z",
     "iopub.status.idle": "2021-02-11T12:15:02.109467Z",
     "shell.execute_reply": "2021-02-11T12:15:02.109885Z"
    },
    "id": "jeV8_FpsiDwH"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TensorFlow Datasets: 4.3.0+nightly\n",
      "2021-06-16 13:16:13.179007: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-06-16 13:16:13.179192: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tfds-nightly\n",
    "!tfds --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdZiDNR1ijRH"
   },
   "source": [
    "For the list of all CLI commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T12:15:02.115830Z",
     "iopub.status.busy": "2021-02-11T12:15:02.114092Z",
     "iopub.status.idle": "2021-02-11T12:15:04.542714Z",
     "shell.execute_reply": "2021-02-11T12:15:04.543111Z"
    },
    "id": "CCJPO_Akij0U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tfds [-h] [--helpfull] [--version] {build,new} ...\r\n",
      "\r\n",
      "Tensorflow Datasets CLI tool\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help   show this help message and exit\r\n",
      "  --helpfull   show full help message and exit\r\n",
      "  --version    show program's version number and exit\r\n",
      "\r\n",
      "command:\r\n",
      "  {build,new}\r\n",
      "    build      Commands for downloading and preparing datasets.\r\n",
      "    new        Creates a new dataset directory from the template.\r\n"
     ]
    }
   ],
   "source": [
    "!tfds --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJrFRBDKj0sO"
   },
   "source": [
    "## `tfds new`: Implementing a new Dataset\n",
    "\n",
    "This command will help you kickstart writing your new Python dataset by creating\n",
    "a `<dataset_name>/` directory containing default implementation files.\n",
    "\n",
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T12:15:04.550018Z",
     "iopub.status.busy": "2021-02-11T12:15:04.549413Z",
     "iopub.status.idle": "2021-02-11T12:15:06.993443Z",
     "shell.execute_reply": "2021-02-11T12:15:06.994004Z"
    },
    "id": "c0Bm7yFCk91Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generated at /tmpfs/src/temp/docs/my_dataset\r\n",
      "You can start searching `TODO(my_dataset)` to complete the implementation.\r\n",
      "Please check https://www.tensorflow.org/datasets/add_dataset for additional details.\r\n"
     ]
    }
   ],
   "source": [
    "!tfds new my_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZaDtK0elimF"
   },
   "source": [
    "Will create:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T12:15:07.000389Z",
     "iopub.status.busy": "2021-02-11T12:15:06.998415Z",
     "iopub.status.idle": "2021-02-11T12:15:07.109656Z",
     "shell.execute_reply": "2021-02-11T12:15:07.110065Z"
    },
    "id": "CwSPLFRfli8I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py\r\n",
      "checksums.tsv\r\n",
      "\u001b[0m\u001b[01;34mdummy_data\u001b[0m/\r\n",
      "my_dataset.py\r\n",
      "my_dataset_test.py\r\n"
     ]
    }
   ],
   "source": [
    "ls -1 my_dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUsoDbi0moyK"
   },
   "source": [
    "See our [writing dataset guide](https://www.tensorflow.org/datasets/add_dataset)\n",
    "for more info.\n",
    "\n",
    "Available options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T12:15:07.116829Z",
     "iopub.status.busy": "2021-02-11T12:15:07.116195Z",
     "iopub.status.idle": "2021-02-11T12:15:09.517398Z",
     "shell.execute_reply": "2021-02-11T12:15:09.516786Z"
    },
    "id": "pAWCw-fDkwky"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tfds new [-h] [--helpfull] [--dir DIR] dataset_name\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  dataset_name  Name of the dataset to be created (in snake_case)\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help    show this help message and exit\r\n",
      "  --helpfull    show full help message and exit\r\n",
      "  --dir DIR     Path where the dataset directory will be created. Defaults to\r\n",
      "                current directory.\r\n"
     ]
    }
   ],
   "source": [
    "!tfds new --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7996uhD1-GP"
   },
   "source": [
    "## `tfds build`: Download and prepare a dataset\n",
    "\n",
    "Use `tfds build <my_dataset>` to generate a new dataset. `<my_dataset>` can be:\n",
    "\n",
    "* A path to `dataset/` folder or `dataset.py` file (empty for current directory):\n",
    "  * `tfds build datasets/my_dataset/`\n",
    "  * `cd datasets/my_dataset/ && tfds build`\n",
    "  * `cd datasets/my_dataset/ && tfds build my_dataset`\n",
    "  * `cd datasets/my_dataset/ && tfds build my_dataset.py`\n",
    "\n",
    "* A registered dataset:\n",
    "\n",
    "  * `tfds build mnist`\n",
    "  * `tfds build my_dataset --imports my_project.datasets`\n",
    "\n",
    "Note: `tfds build` has useful flags to help prototyping and debuging. See the `Debug & tests:` section bellow.\n",
    "\n",
    "Available options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-11T12:15:09.524697Z",
     "iopub.status.busy": "2021-02-11T12:15:09.524072Z",
     "iopub.status.idle": "2021-02-11T12:15:11.960564Z",
     "shell.execute_reply": "2021-02-11T12:15:11.960944Z"
    },
    "id": "IGAl6dw62KNO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tfds build [-h] [--helpfull]\r\n",
      "                  [--datasets DATASETS_KEYWORD [DATASETS_KEYWORD ...]]\r\n",
      "                  [--overwrite]\r\n",
      "                  [--max_examples_per_split [MAX_EXAMPLES_PER_SPLIT]]\r\n",
      "                  [--data_dir DATA_DIR] [--download_dir DOWNLOAD_DIR]\r\n",
      "                  [--extract_dir EXTRACT_DIR] [--manual_dir MANUAL_DIR]\r\n",
      "                  [--add_name_to_manual_dir] [--config CONFIG]\r\n",
      "                  [--config_idx CONFIG_IDX] [--imports IMPORTS]\r\n",
      "                  [--register_checksums] [--force_checksums_validation]\r\n",
      "                  [--beam_pipeline_options BEAM_PIPELINE_OPTIONS]\r\n",
      "                  [--exclude_datasets EXCLUDE_DATASETS]\r\n",
      "                  [--experimental_latest_version]\r\n",
      "                  [datasets [datasets ...]]\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  datasets              Name(s) of the dataset(s) to build. Default to current\r\n",
      "                        dir. See https://www.tensorflow.org/datasets/cli for\r\n",
      "                        accepted values.\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --helpfull            show full help message and exit\r\n",
      "  --datasets DATASETS_KEYWORD [DATASETS_KEYWORD ...]\r\n",
      "                        Datasets can also be provided as keyword argument.\r\n",
      "\r\n",
      "Debug & tests:\r\n",
      "  --pdb Enter post-mortem debugging mode if an exception is raised.\r\n",
      "\r\n",
      "  --overwrite           Delete pre-existing dataset if it exists.\r\n",
      "  --max_examples_per_split [MAX_EXAMPLES_PER_SPLIT]\r\n",
      "                        When set, only generate the first X examples (default\r\n",
      "                        to 1), rather than the full dataset.If set to 0, only\r\n",
      "                        execute the `_split_generators` (which download the\r\n",
      "                        original data), but skip `_generator_examples`\r\n",
      "\r\n",
      "Paths:\r\n",
      "  --data_dir DATA_DIR   Where to place datasets. Default to\r\n",
      "                        `~/tensorflow_datasets/` or `TFDS_DATA_DIR`\r\n",
      "                        environement variable.\r\n",
      "  --download_dir DOWNLOAD_DIR\r\n",
      "                        Where to place downloads. Default to\r\n",
      "                        `<data_dir>/downloads/`.\r\n",
      "  --extract_dir EXTRACT_DIR\r\n",
      "                        Where to extract files. Default to\r\n",
      "                        `<download_dir>/extracted/`.\r\n",
      "  --manual_dir MANUAL_DIR\r\n",
      "                        Where to manually download data (required for some\r\n",
      "                        datasets). Default to `<download_dir>/manual/`.\r\n",
      "  --add_name_to_manual_dir\r\n",
      "                        If true, append the dataset name to the `manual_dir`\r\n",
      "                        (e.g. `<download_dir>/manual/<dataset_name>/`. Useful\r\n",
      "                        to avoid collisions if many datasets are generated.\r\n",
      "\r\n",
      "Generation:\r\n",
      "  --config CONFIG, -c CONFIG\r\n",
      "                        Config name to build. Build all configs if not set.\r\n",
      "  --config_idx CONFIG_IDX\r\n",
      "                        Config id to build\r\n",
      "                        (`builder_cls.BUILDER_CONFIGS[config_idx]`). Mutually\r\n",
      "                        exclusive with `--config`.\r\n",
      "  --imports IMPORTS, -i IMPORTS\r\n",
      "                        Comma separated list of module to import to register\r\n",
      "                        datasets.\r\n",
      "  --register_checksums  If True, store size and checksum of downloaded files.\r\n",
      "  --force_checksums_validation\r\n",
      "                        If True, raise an error if the checksums are not\r\n",
      "                        found.\r\n",
      "  --beam_pipeline_options BEAM_PIPELINE_OPTIONS\r\n",
      "                        A (comma-separated) list of flags to pass to\r\n",
      "                        `PipelineOptions` when preparing with Apache Beam.\r\n",
      "                        (see:\r\n",
      "                        https://www.tensorflow.org/datasets/beam_datasets).\r\n",
      "                        Example: `--beam_pipeline_options=job_name=my-\r\n",
      "                        job,project=my-project`\r\n",
      "\r\n",
      "Automation:\r\n",
      "  Used by automated scripts.\r\n",
      "\r\n",
      "  --exclude_datasets EXCLUDE_DATASETS\r\n",
      "                        If set, generate all datasets except the one defined\r\n",
      "                        here. Comma separated list of datasets to exclude.\r\n",
      "  --experimental_latest_version\r\n",
      "                        Build the latest Version(experiments=...) available\r\n",
      "                        rather than default version.\r\n"
     ]
    }
   ],
   "source": [
    "!tfds build --help"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "kGrmMPUhXfUs"
   ],
   "name": "tensorflow/datasets",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "interpreter": {
   "hash": "368f130a54ee9f8794746d50752fdca9c995da24628fbde72b06a701d3e4917a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}